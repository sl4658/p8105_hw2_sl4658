---
title: "p8105_hw2_sl4658"
author: "Simin Ling"
date: "9/30/2020"
output: github_document
---

```{r, message=FALSE}
library(tidyverse)
library(readxl)
```


## Problem 1
Read and clean the Mr. Trash Wheel dataset.
```{r}
trashwheel_df = 
  read_excel("~/Desktop/Fall 2020/Data Science/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
            sheet = "Mr. Trash Wheel", 
            range = "A2:N408") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = round(sports_balls),
         sports_balls = as.integer(sports_balls))
```

Read and clean precipitation data for 2017
```{r}
precip_2017_df = 
  read_excel("~/Desktop/Fall 2020/Data Science/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
            sheet = "2017 Precipitation", 
            range = "A2:B14") %>%
  janitor::clean_names() %>%
  mutate(year = 2017)
```

Read and clean precipitation data for 2018
```{r}
precip_2018_df = 
  read_excel("~/Desktop/Fall 2020/Data Science/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
            sheet = "2018 Precipitation", 
            range = "A2:B14") %>%
  janitor::clean_names() %>%
  mutate(year = 2018)
```

Combine precipitation datasets and convert month to a character variable
```{r}
month_df = tibble(month = 1:12,
                  month_name = month.name)

precip_comb = bind_rows(precip_2017_df,precip_2018_df)
  
precip_comb = 
  left_join(precip_comb, month_df, by = "month")
```


There are `r nrow(trashwheel_df)` observations in the Mr. Trash Wheel dataset, and `r nrow(precip_comb)` observations in the combined precipitation dataset (2017 and 2018). 

Some important variables in the Mr. Trash Wheel dataset include the dumpster site #, time information on trash collection (year, month and date), weight and volume of trash that was collected, and types and quantity of the trash. Some important variables in the combined precipitation dataset (2017 and 2018) include the month and year of the measurement on precipitation, and the total precipitation in that specific time measured in inches.

The total precipitation in 2018 is `r sum(select(precip_2018_df, total))` inches.

The median number of sports balls in a dumpster in 2017 is `r median(filter(trashwheel_df, year == "2017")$sports_balls)`.




## Problem 2

Read and clean the NYC Transit data.
```{r, message=FALSE}
nyc = 
  read_csv("~/Desktop/Fall 2020/Data Science/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) 
  nyc$entry <- ifelse(nyc$entry == "YES", "TRUE",  "FALSE")
```
** Description on Dataset **

This dataset contains information on the NYC subway station's name, location, division and line, routes, entrance type and location, availability of vending machine, ADA compliance and staff-related information (staffing status and staff hours).

I cleaned the variable names into a standard formal style, selected only the important variables according to the homework instruction, and converted the entry variable from character (Yes vs No) to a logical variable (True vs False). There are `r nrow(nyc)` rows and `r ncol(nyc)` columns in the dataset, the dimension of the dataset is `r nrow(nyc)*ncol(nyc)`.

The data is not tidy, because the vending variable in the dataset still need to convert from character to logical (convert from YES vs NO to TRUE vs FALSE), and there are too many columns for routes that are redundant. 

** Answers to the Homework Questions **
```{r}
dist_stat = distinct(nyc, station_name, line, .keep_all = TRUE)
vending_wo = filter(nyc, vending == "NO")
dist_stat
```

Question 1. 
There are `r nrow(dist_stat)` distinct stations.

Question 2. 
The number of stations that are ADA compliant is `r nrow(filter(dist_stat, ada == "TRUE"))`.

Question 3.
The proportion of station entrances/exits without vending allow entrance is `r nrow(filter(vending_wo, entry == "TRUE"))/nrow(vending_wo)`. 


** Reformat the Data **
```{r}
dist_stat = 
  dist_stat %>%
  mutate_at(vars(route8:route11), as.character) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number")
```

There are `r nrow(filter(dist_stat, route_number == "A"))` distinct stations serve the A train. 

Of the stations that serve the A train, there are `r nrow(filter(dist_stat, route_number == "A", ada == "TRUE"))` ADA compliant stations.



## Problem 3

Read and clean the pols-month data
```{r, message = FALSE}
pols_month_df = 
  read_csv("~/Desktop/Fall 2020/Data Science/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(year = as.integer(year),
         month = as.integer(month),
         day = as.integer(day))%>%
  mutate(month = month.abb[month]) %>%
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>%
  select(-c(prez_gop, prez_dem, day))
```

Read and clean the snp data
```{r, message = FALSE}
snp_df = 
  read_csv("~/Desktop/Fall 2020/Data Science/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>% 
  mutate(year = as.integer(year),
         month = as.integer(month),
         day = as.integer(day))%>%
  mutate(month = month.abb[month]) %>%
  select(-day) %>%
  arrange(year, month) %>%
  relocate(year, month)
```

Tidy the unemployment data
```{r, message = FALSE}
unemploy_df = 
  read_csv("~/Desktop/Fall 2020/Data Science/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment") %>%
  janitor::clean_names() %>%
  mutate(year = as.integer(year)) 
```

Merge all the dataset together
```{r}
merged_pols_snp = 
  left_join(pols_month_df, snp_df, by = c("year", "month"))

merged_pols_snp_unemploy = 
  left_join(merged_pols_snp, unemploy_df, by = c("year", "month"))
```


** Paragraph description on the dataset **

The pols_month dataset contains information on the number of national politicians (e.g.: governors, senators, representatives, president) who are democratic or republican at a specific time (year, month, day).

The snp dataset contains information on observation of Standard&Poor's stock market index (S&P), including the date of observation (year, month, day) and the closing values of the S&P stock index on that date. 

The unemployment dataset contains information on the percentage of unemployment at a specific time (year, month).

The resulting merged dataset has `r nrow(merged_pols_snp_unemploy)` rows and `r ncol(merged_pols_snp_unemploy)` columns. The range of years in the merged dataset is from `r min(merged_pols_snp_unemploy$year)` to `r max(merged_pols_snp_unemploy$year)`. The full list of variables and their related information are listed in the table below: 

```{r}
summary(merged_pols_snp_unemploy)
```

Some key variables in the merged dataset include the year and month of each observation, number of national politicians who are democratic or republican at that time, and the closing values of the S&P stock index on that time.

