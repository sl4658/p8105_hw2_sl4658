p8105\_hw2\_sl4658
================
Simin Ling
9/30/2020

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

Define the pathway to Mr. Trash Wheel dataset.

``` r
path_trashwheel = "./Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

Read and clean the Mr. Trash Wheel dataset.

``` r
trashwheel_df = 
  read_excel(path = path_trashwheel, 
            sheet = "Mr. Trash Wheel", 
            range = "A2:N408") %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = round(sports_balls),
         sports_balls = as.integer(sports_balls))
```

Read and clean precipitation data for 2017

``` r
precip_2017_df = 
  read_excel(path = path_trashwheel, 
            sheet = "2017 Precipitation", 
            range = "A2:B14") %>%
  janitor::clean_names() %>%
  mutate(year = 2017)
```

Read and clean precipitation data for 2018

``` r
precip_2018_df = 
  read_excel(path = path_trashwheel, 
            sheet = "2018 Precipitation", 
            range = "A2:B14") %>%
  janitor::clean_names() %>%
  mutate(year = 2018)
```

Combine precipitation datasets and convert month to a character variable

``` r
month_df = tibble(month = 1:12,
                  month_name = month.name)

precip_comb = bind_rows(precip_2017_df,precip_2018_df)
  
precip_comb = 
  left_join(precip_comb, month_df, by = "month")
```

There are 344 observations in the Mr. Trash Wheel dataset, and 24
observations in the combined precipitation dataset (2017 and 2018).

Some important variables in the Mr. Trash Wheel dataset include the
dumpster site \#, time information on trash collection (year, month and
date), weight and volume of trash that was collected, and types and
quantity of the trash. Some important variables in the combined
precipitation dataset (2017 and 2018) include the month and year of the
measurement on precipitation, and the total precipitation in that
specific time measured in inches.

The total precipitation in 2018 is 70.33 inches.

The median number of sports balls in a dumpster in 2017 is 8.

## Problem 2

Define the pathway to NYC Transit dataset.

``` r
path_nyc = "./NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
```

Read and clean the NYC Transit dataset.

``` r, message=FALSE
nyc = 
  read_csv(path_nyc) %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) 
  nyc$entry <- ifelse(nyc$entry == "YES", "TRUE",  "FALSE")
```

\*\* Description on Dataset \*\*

This dataset contains information on the NYC subway station’s name,
location, division and line, routes, entrance type and location,
availability of vending machine, ADA compliance and staff-related
information (staffing status and staff hours).

I cleaned the variable names into a standard formal style, selected only
the important variables according to the homework instruction, and
converted the entry variable from character (Yes vs No) to a logical
variable (True vs False). There are 1868 rows and 19 columns in the
dataset, the dimension of the dataset is 35492.

The data is not tidy, because the vending variable in the dataset still
need to convert from character to logical (convert from YES vs NO to
TRUE vs FALSE), and there are too many columns for routes that are
redundant.

\*\* Answers to the Homework Questions \*\*

``` r
dist_stat = distinct(nyc, station_name, line, .keep_all = TRUE)
vending_wo = filter(nyc, vending == "NO")

```

Question 1. There are 465 distinct stations.

Question 2. The number of stations that are ADA compliant is 84.

Question 3. The proportion of station entrances/exits without vending
allow entrance is 0.3770492.

\*\* Reformat the Data \*\*

``` r
dist_stat = 
  dist_stat %>%
  mutate_at(vars(route8:route11), as.character) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number")
```

There are 60 distinct stations serve the A train.

Of the stations that serve the A train, there are 17 ADA compliant
stations.

## Problem 3

Read and clean the pols-month data

``` r
pols_month_df = 
  read_csv("~/Desktop/Fall 2020/Data Science/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(year = as.integer(year),
         month = as.integer(month),
         day = as.integer(day))%>%
  mutate(month = month.abb[month]) %>%
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>%
  select(-c(prez_gop, prez_dem, day))
```

Read and clean the snp data

``` r
snp_df = 
  read_csv("~/Desktop/Fall 2020/Data Science/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>% 
  mutate(year = as.integer(year),
         month = as.integer(month),
         day = as.integer(day))%>%
  mutate(month = month.abb[month]) %>%
  select(-day) %>%
  arrange(year, month) %>%
  relocate(year, month)
```

Tidy the unemployment data

``` r
unemploy_df = 
  read_csv("~/Desktop/Fall 2020/Data Science/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment") %>%
  janitor::clean_names() %>%
  mutate(year = as.integer(year)) 
```

Merge all the dataset together

``` r
merged_pols_snp = 
  left_join(pols_month_df, snp_df, by = c("year", "month"))

merged_pols_snp_unemploy = 
  left_join(merged_pols_snp, unemploy_df, by = c("year", "month"))
```

\*\* Paragraph description on the dataset \*\*

The pols\_month dataset contains information on the number of national
politicians (e.g.: governors, senators, representatives, president) who
are democratic or republican at a specific time (year, month, day).

The snp dataset contains information on observation of Standard\&Poor’s
stock market index (S\&P), including the date of observation (year,
month, day) and the closing values of the S\&P stock index on that date.

The unemployment dataset contains information on the percentage of
unemployment at a specific time (year, month).

The resulting merged dataset has 822 rows and 11 columns. The range of
years in the merged dataset is from 1947 to 2015. The full list of
variables and their related information are listed in the table below:

``` r
summary(merged_pols_snp_unemploy)
```

    ##       year         month              gov_gop         sen_gop    
    ##  Min.   :1947   Length:822         Min.   :12.00   Min.   :32.0  
    ##  1st Qu.:1964   Class :character   1st Qu.:18.00   1st Qu.:42.0  
    ##  Median :1981   Mode  :character   Median :22.00   Median :46.0  
    ##  Mean   :1981                      Mean   :22.48   Mean   :46.1  
    ##  3rd Qu.:1998                      3rd Qu.:28.00   3rd Qu.:51.0  
    ##  Max.   :2015                      Max.   :34.00   Max.   :56.0  
    ##                                                                  
    ##     rep_gop         gov_dem        sen_dem         rep_dem   
    ##  Min.   :141.0   Min.   :17.0   Min.   :44.00   Min.   :188  
    ##  1st Qu.:176.0   1st Qu.:22.0   1st Qu.:48.00   1st Qu.:211  
    ##  Median :195.0   Median :28.0   Median :53.00   Median :250  
    ##  Mean   :194.9   Mean   :27.2   Mean   :54.41   Mean   :245  
    ##  3rd Qu.:222.0   3rd Qu.:32.0   3rd Qu.:58.00   3rd Qu.:268  
    ##  Max.   :253.0   Max.   :41.0   Max.   :71.00   Max.   :301  
    ##                                                              
    ##   president             close          unemployment  
    ##  Length:822         Min.   :  17.05   Min.   : 2.50  
    ##  Class :character   1st Qu.:  83.67   1st Qu.: 4.70  
    ##  Mode  :character   Median : 137.26   Median : 5.60  
    ##                     Mean   : 472.85   Mean   : 5.83  
    ##                     3rd Qu.: 932.06   3rd Qu.: 6.90  
    ##                     Max.   :2107.39   Max.   :10.80  
    ##                     NA's   :36        NA's   :12

Some key variables in the merged dataset include the year and month of
each observation, number of national politicians who are democratic or
republican at that time, and the closing values of the S\&P stock index
on that time.
